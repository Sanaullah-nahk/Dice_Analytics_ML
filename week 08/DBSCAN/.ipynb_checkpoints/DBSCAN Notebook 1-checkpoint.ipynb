{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN Lab\n",
    "In this notebook, we will use DBSCAN to cluster a couple of data sets. We will examine how changing its parameters (epsilon and min_samples) changes the resulting cluster structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1:** Import *\"pandas\"* library and read the csv file *\"Blobs.csv\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write code here\n",
    "\n",
    "df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_1= df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This our first dataset. It looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import dbscan_lab_helper as helper    \n",
    "helper.plot_dataset(dataset_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's cluster it using DBSCAN's default settings and see what happens. We are hoping for it to be able to assign each of the three \"blobs\" into its own cluster. Can it do that out of the box?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2:** Do the following tasks:\n",
    "<br/>a) Import sklearn's cluster module\n",
    "<br/>b) Create an instance of DBSCAN\n",
    "<br/>c) Use DBSCAN's fit_predict to return clustering labels for dataset_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write code for task a\n",
    "\n",
    "\n",
    "#Write code for task b\n",
    "dbscan = None\n",
    "\n",
    "#Write code for task c\n",
    "clustering_labels_1 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot clustering\n",
    "helper.plot_clustered_dataset(dataset_1, clustering_labels_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does that look okay? Was it able to group the dataset into the three clusters we were hoping for?\n",
    "\n",
    "As you see, we will have to make some tweaks. Let's start by looking at Epsilon, the radius of each point's neighborhood. The default value in sklearn is 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot clustering with neighborhoods\n",
    "helper.plot_clustered_dataset(dataset_1, clustering_labels_1, neighborhood=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graph, we can see that an Epsilon value of 0.5 is too small for this dataset. We need to increase it so the points in a blob overlap each others' neighborhoods, but not to the degree where a single cluster would span two blobs.\n",
    "\n",
    "**Task 3:** Change the value of Epsilon so that each blob is its own cluster (without any noise points). The graph shows  the points in the datasets as well as the neighborhood of each point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change the value epsilon below\n",
    "epsilon= None\n",
    "\n",
    "# Cluster\n",
    "dbscan = cluster.DBSCAN(eps=epsilon)\n",
    "clustering_labels_2 = dbscan.fit_predict(dataset_1)\n",
    "\n",
    "# Plot\n",
    "helper.plot_clustered_dataset(dataset_1, clustering_labels_2, neighborhood=True, epsilon=epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Were you able to do it? As you change the values, you can see that the points cluster into larger clusters and the number of noise points keeps on decreasing. Then at Epsilon values above 1.6 we get the clustering we're after. But once we increase it to above 5, we start to see two blobs joining together into one cluster. So the right Epsilon would be in the range between those values in this scenario.\n",
    "\n",
    "## Dataset 2\n",
    "\n",
    "Let's now look at a dataset that's a little more tricky"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4:** Import the csv file *\"Varied.csv\"* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write code here\n",
    "df2= "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_2= df2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "helper.plot_dataset(dataset_2, xlim=(-14, 5), ylim=(-12, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we run DBSCAN with the default parameter values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 5:** Do the following tasks:\n",
    "<br/>a) Create an instance of DBSCAN\n",
    "<br/>b) Use DBSCAN's fit_predict to return clustering labels for dataset_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code for task a\n",
    "dbscan = \n",
    "\n",
    "# Write code for task b\n",
    "clustering_labels_3 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "helper.plot_clustered_dataset(dataset_2, \n",
    "                              clustering_labels_3, \n",
    "                              xlim=(-14, 5), \n",
    "                              ylim=(-12, 7), \n",
    "                              neighborhood=True, \n",
    "                              epsilon=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This clustering could make sense in some scenarios, but it seems rather arbitrary. Looking at the dataset, we can imagine at least two scenarios for what we'd want to do:\n",
    " * **Scenario** 1: Break the dataset up into three clusters: the blob on the left, the blob on the right, and the central area (even though it's less dense than the blobs on either side).\n",
    " * **Scenario 2**: Break the dataset up into two clusters: the blob on the left, and the blob on the right. Marking all the points in the center as noise. \n",
    " \n",
    "What values for the DBSCAN parameters would allow us to satisfy each of those senarios? Try a number of parameters to see if you can find a clustering that makes more sense.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6:** Experiment with different values for eps and min_samples to find a suitable clustering for the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the values below\n",
    "eps=None\n",
    "min_samples=None\n",
    "\n",
    "# Cluster with DBSCAN\n",
    "dbscan = cluster.DBSCAN(eps=eps, min_samples=min_samples)\n",
    "clustering_labels_4 = dbscan.fit_predict(dataset_2)\n",
    "\n",
    "# Plot\n",
    "helper.plot_clustered_dataset(dataset_2, \n",
    "                              clustering_labels_4, \n",
    "                              xlim=(-14, 5), \n",
    "                              ylim=(-12, 7), \n",
    "                              neighborhood=True, \n",
    "                              epsilon=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The following grid plots the DBSCAN clustering results of a range of parameter values. Epsilon varies horizontally, while vertically each row shows a different value of min_samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "eps_values = [0.3, 0.5, 1, 1.3, 1.5]\n",
    "min_samples_values = [2, 5, 10, 20, 80]\n",
    "\n",
    "helper.plot_dbscan_grid(dataset_2, eps_values, min_samples_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Heuristics for experimenting with DBSCAN's parameters\n",
    "Looking at this grid, we can guess at some general heuristics for tweaking the parameters of DBSCAN:\n",
    "\n",
    "<img src='images/low_epsilon_and_low_min_sample.png'><br>Many small clusters. More than anticipated for the dataset. <br>**Action**: increase min_samples and epsilon| <img src='images/high_epsilon_and_low_min_sample.png'><br>Most points belong to one cluster<br>**Action**: decrease epsilon and increase min_samples|\n",
    "<img src='images/low_epsilon_and_high_min_sample.png'><br>Most/all data points are labeled as noise<br>**Action**: increase epsilon and decrease min_sample <img src='images/high_epsilon_and_high_min_sample.png'><br> Except for extremely dense regions, most/all data points are <br>labeled as noise. (Or all points are labeled as noise). <br>**Action**: decrease min_samples and epsilon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz\n",
    "* Which values do you believe best satisfy scenario 1? \n",
    "* Which values do you believe best satisfy scenario 2?\n",
    "\n",
    "### Answers:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give your answers here:\n",
    "<br/>1:\n",
    "<br/>2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DBCV i.e. Density-Based Clustering Validation is another technique for clustering validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moulavi, Davoud, et al. \"Density-based clustering validation.\" Proceedings of the 2014 SIAM International Conference on Data Mining. Society for Industrial and Applied Mathematics, 2014.\n",
    "\n",
    "[Link](https://epubs.siam.org/doi/pdf/10.1137/1.9781611973440.96)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is DBCV?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do you validate clustering assignmnets from unsupervised learning algorithms? A common method is the Silhoette Method, which provides an objective score between -1 and 1 on the quality of clustering. The silhouette value measures how well an object is classified in its own cluster instead of neighboring clusters. The silhouette (and most other popular methods) work very well on globular clusters, but can fail on non-glubular clusters.\n",
    "\n",
    "Here, we implement DBCV which can validate clustering assignments on non-globular, arbitrarily shaped clusters . In essence, DBCV computes two values:\n",
    "\n",
    "- The density within a cluster\n",
    "- The density between clusters\n",
    "\n",
    "High density within a cluster, and low density between clusters indicates good clustering assignments. Let us have a look at the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "n_samples=250\n",
    "noisy_moons = datasets.make_circles(n_samples=n_samples, noise=.03,factor=0.5)\n",
    "X = noisy_moons[0]\n",
    "plt.scatter(X[:,0], X[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans =  KMeans(n_clusters=2, random_state=0)\n",
    "kmeans_labels = kmeans.fit_predict(X)\n",
    "plt.scatter(X[:,0], X[:,1], c=kmeans_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not so great. Let us check the **Silhouette Score** for these clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "metrics.silhouette_score(X, kmeans_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the **Silhouette Score** is not as bad as the clusters made. Let us apply DBSCAN and validate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cluster\n",
    "\n",
    "dbscanner = cluster.DBSCAN(eps=0.3, min_samples=20)\n",
    "dbscan_labels = dbscanner.fit_predict(X)\n",
    "plt.scatter(X[:,0], X[:,1], c=dbscan_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating the above clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Silhouette Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.silhouette_score(X, dbscan_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying DBCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import euclidean\n",
    "import dbscan_lab_helper as helper\n",
    "\n",
    "kmeans_score = helper.DBCV(X, kmeans_labels, dist_function=euclidean)\n",
    "dbscan_score = helper.DBCV(X, dbscan_labels, dist_function=euclidean)\n",
    "\n",
    "print('KMeans Score for Circles is:', kmeans_score)\n",
    "print('DBSCAN Score for Circles is:', dbscan_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please note that DBCV gives more accurate scores for the clusters made through K-Means and DBSCAN.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
